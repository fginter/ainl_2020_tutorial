{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parser-tnpp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b021fa78cd04691854bd38fa26feac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2bf52f6d9d654a67ad5b83d7714a2f94",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a735b6868eb457cb5c70617a5a0001f",
              "IPY_MODEL_150045ba57844f6398c2e581872a3de1"
            ]
          }
        },
        "2bf52f6d9d654a67ad5b83d7714a2f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a735b6868eb457cb5c70617a5a0001f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da2e42939a474f0ebe2baf385a330059",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 424343,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 424343,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16888e78287540a482ecc04b8568ae0e"
          }
        },
        "150045ba57844f6398c2e581872a3de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d07cdb088a324346bc45b4dda510fd19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 424k/424k [00:00&lt;00:00, 3.39MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a8205f6e4424dbb806d5ac9efc2b5c9"
          }
        },
        "da2e42939a474f0ebe2baf385a330059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16888e78287540a482ecc04b8568ae0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d07cdb088a324346bc45b4dda510fd19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a8205f6e4424dbb806d5ac9efc2b5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fginter/ainl_2020_tutorial/blob/main/parser_tnpp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCRShOw-W9Fk"
      },
      "source": [
        "# Turku Neural Parser Pipeline - Python module version\n",
        "\n",
        "* This is a basic tutorial for running the parser pipeline under Google Colab\n",
        "* Many new properties added for the AINL2020 tutorial\n",
        "  * Parser changed to Udify (87->91% LAS improvement)\n",
        "  * Code restructured so as to be importable as a module and can be installed using pip\n",
        "  * No longer depends on Tensorflow\n",
        "* Makes it possible for anyone to run the parser with GPU acceleration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byCtKqKGX-Yy"
      },
      "source": [
        "# Install\n",
        "\n",
        "* Pre-built wheel, not yet in PyPi\n",
        "* Only Finnish and English models in this tutorial, more coming!\n",
        "\n",
        "## Install the parser package (takes its time)\n",
        "\n",
        "`pip3 install http://dl.turkunlp.org/turku-parser-models/turku_neural_parser-0.2-py3-none-any.whl`\n",
        "\n",
        "## Download and unpack the model\n",
        "\n",
        "`wget http://dl.turkunlp.org/turku-parser-models/models_fi_tdt.tar.gz ; tar zxvf models_fi_tdt.tar.gz`\n",
        "\n",
        "...and you are good to go!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM38KujEb2dT"
      },
      "source": [
        "# Prerequisites:\n",
        "\n",
        "* At this point you need torch 1.6\n",
        "* Google colab comes (right now) with python 3.6, cuda 10.1\n",
        "* So we need to find the correct installation instructions here: https://pytorch.org/get-started/previous-versions/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_klczVZaSpJ",
        "outputId": "20568af4-4544-47ab-8bb9-6eb6e64f8b82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version\n",
        "!python -V"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyJzHSqbbP8S",
        "outputId": "e73346f4-2b8a-47c2-dbaa-bc091e943415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 60.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3zn4zrJwAEB",
        "outputId": "05599ac8-5c42-4300-d322-4f27fe6f76c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Gdown is a utility for downloading large files from Google Drive, where I mirrored the NER trained model for you\n",
        "#The current models need torch 1.6 and die with torch 1.7, this will be eventually fixed\n",
        "\n",
        "!pip3 install gdown\n",
        "!gdown -O turku_neural_parser-0.2-py3-none-any.whl 'https://drive.google.com/uc?export=download&id=1m8Nhd1oU6eS559D0Xboe83NbTzcMsyjN'\n",
        "\n",
        "!pip3 install turku_neural_parser-0.2-py3-none-any.whl"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1m8Nhd1oU6eS559D0Xboe83NbTzcMsyjN\n",
            "To: /content/turku_neural_parser-0.2-py3-none-any.whl\n",
            "100% 44.4k/44.4k [00:00<00:00, 34.0MB/s]\n",
            "Processing ./turku_neural_parser-0.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from turku-neural-parser==0.2) (2.23.0)\n",
            "Collecting unofficial-udify==0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/de/571ad276bf1f45c4dba5ac76bec3ecd88ef362b6b0d649774b1e89a1e198/unofficial_udify-0.1.3-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from turku-neural-parser==0.2) (1.18.5)\n",
            "Collecting ufal.udpipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 21.2MB/s \n",
            "\u001b[?25hCollecting configargparse\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/79/3045743bb26ca2e44a1d317c37395462bfed82dbbd38e69a3280b63696ce/ConfigArgParse-1.2.3.tar.gz (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from turku-neural-parser==0.2) (1.1.2)\n",
            "Collecting torchtext==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f9/224b3893ab11d83d47fde357a7dcc75f00ba219f34f3d15e06fe4cb62e05/torchtext-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from turku-neural-parser==0.2) (3.13)\n",
            "Collecting OpenNMT-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->turku-neural-parser==0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->turku-neural-parser==0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->turku-neural-parser==0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->turku-neural-parser==0.2) (2020.11.8)\n",
            "Collecting transformers<3.0.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 51.1MB/s \n",
            "\u001b[?25hCollecting unofficial-allennlp-nightly==0.9.1.dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/73/166dda68e52509004bcabafed90d5e986d10810988d5aa1ab735dec1c8a1/unofficial_allennlp_nightly-0.9.1.dev0-py3-none-any.whl (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->turku-neural-parser==0.2) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->turku-neural-parser==0.2) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->turku-neural-parser==0.2) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->turku-neural-parser==0.2) (7.1.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.7.0->turku-neural-parser==0.2) (1.6.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.7.0->turku-neural-parser==0.2) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py->turku-neural-parser==0.2) (1.15.0)\n",
            "Collecting waitress\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/d1/5209fb8c764497a592363c47054436a515b47b8c3e4970ddd7184f088857/waitress-1.4.4-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py->turku-neural-parser==0.2) (0.16.0)\n",
            "Collecting pyonmttok==1.*; platform_system == \"Linux\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/21/7a69fa68de7de41ef70b35424d21523ebf2208f0c0fab1355cabc2305ff4/pyonmttok-1.22.2-cp36-cp36m-manylinux1_x86_64.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py->turku-neural-parser==0.2) (2.3.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.0.0,>=2.3.0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.0.0,>=2.3.0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.0.0,>=2.3.0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.0.0,>=2.3.0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (3.0.12)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 53.1MB/s \n",
            "\u001b[?25hCollecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (3.2.5)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.2.4)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.4.1)\n",
            "Collecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hCollecting overrides==2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/b2/2cb6a3fc8ee1dc8617e07e476be19723748ddfcce0c6b9db7a5f2d5b9598/overrides-2.0.tar.gz\n",
            "Collecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/71/4f04aed03ca35f2d02e1732ca6e996b2d7b40232fb7f1b58ff35f9a89b7b/responses-0.12.1-py2.py3-none-any.whl\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 49.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (3.6.4)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.4.1)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.5.3)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (3.2.2)\n",
            "Collecting python-dateutil<2.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2018.9)\n",
            "Collecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/43/0e/2f50064e327f41a1eb811df089f813036e19a64b95e33f8e9e0b96c2447e/flaky-3.7.0-py2.py3-none-any.whl\n",
            "Collecting numpydoc>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.10.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/a1/d8b9be4f3996265cb4e42dcd0ba72d61d68062ed6d8ce7e26b37cc399455/boto3-1.16.24-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->turku-neural-parser==0.2) (1.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (3.3.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (1.33.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (50.3.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (0.35.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (1.7.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.0.0,>=2.3.0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.0.0,>=2.3.0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.4.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (3.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (8.6.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (20.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.3.1)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.8.5)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.24\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/16/8afd6474045f41bd51002e65862e2066ea2c5de34d0a942e1c4e86098d9a/botocore-1.19.24-py2.py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (3.4.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.2.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.2.4)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.9.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (0.16)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (2.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py->turku-neural-parser==0.2) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.8.0->unofficial-allennlp-nightly==0.9.1.dev0->unofficial-udify==0.1.3->turku-neural-parser==0.2) (1.1.4)\n",
            "Building wheels for collected packages: ufal.udpipe, configargparse, sacremoses, ftfy, parsimonious, overrides, jsonnet, word2number\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp36-cp36m-linux_x86_64.whl size=5625168 sha256=1c5f091c2e2ea7737473a4c2025af9599ea8fd1789241502ddd414380ca75ae8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
            "  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configargparse: filename=ConfigArgParse-1.2.3-cp36-none-any.whl size=19329 sha256=d51997455dcd7792d6ed2d40af0fa157d337585220cf3442b4e39baa50226b23\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d6/53/034032da9498bda2385cd50a51a289e88090b5da2d592b1fdf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=de19c30496bb6b40367e8918d76b1dcf2558e52a273e54d88e0f8e60adec7cd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=3b752ccaa78903e5b5a9689de0b78011ea15ed594fff3dc166986280c0cd4801\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=0275b07e201b57fe4f0c35297ae59d144051f5f3b220ce62efcdf514b224773a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.0-cp36-none-any.whl size=4221 sha256=14ee69d1e13c8d56b420ac6d5b0cbb5a53febb6a956cd3e91aaa46ba916d688d\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/ab/57/d68b6dad468ff96b792770a83229451add2b347b0c12a10300\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp36-cp36m-linux_x86_64.whl size=3387931 sha256=2e18bdae349d1c78c6725f954c186682e4d19c076b28caeff0ad7cbf166e29dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=478c930652a1c06221c49c36468713da0fb63884aca5e7d697b1677cd7498a2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "Successfully built ufal.udpipe configargparse sacremoses ftfy parsimonious overrides jsonnet word2number\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: responses 0.12.1 has requirement urllib3>=1.25.10, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.24 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: opennmt-py 1.2.0 has requirement torchtext==0.4.0, but you'll have torchtext 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, tensorboardX, conllu, ftfy, parsimonious, overrides, responses, jsonpickle, jsonnet, jmespath, python-dateutil, botocore, s3transfer, boto3, pytorch-pretrained-bert, word2number, flaky, numpydoc, unofficial-allennlp-nightly, unofficial-udify, ufal.udpipe, configargparse, torchtext, waitress, pyonmttok, OpenNMT-py, turku-neural-parser\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed OpenNMT-py-1.2.0 boto3-1.16.24 botocore-1.19.24 configargparse-1.2.3 conllu-1.3.1 flaky-3.7.0 ftfy-5.8 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-1.4.1 numpydoc-1.1.0 overrides-2.0 parsimonious-0.8.1 pyonmttok-1.22.2 python-dateutil-2.8.0 pytorch-pretrained-bert-0.6.2 responses-0.12.1 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tensorboardX-2.1 tokenizers-0.7.0 torchtext-0.7.0 transformers-2.11.0 turku-neural-parser-0.2 ufal.udpipe-1.2.0.3 unofficial-allennlp-nightly-0.9.1.dev0 unofficial-udify-0.1.3 waitress-1.4.4 word2number-1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue9vzD93xLyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1186882-e5f4-48f1-e414-3019ca436cf1"
      },
      "source": [
        "!gdown -O models_fi_tdt.tar.gz 'https://drive.google.com/uc?export=download&id=157r-qRi0YxuN82U252I4RHOXDPv-PgXg'\n",
        "!tar zxvf models_fi_tdt.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=157r-qRi0YxuN82U252I4RHOXDPv-PgXg\n",
            "To: /content/models_fi_tdt.tar.gz\n",
            "1.11GB [00:05, 213MB/s]\n",
            "models_fi_tdt/\n",
            "models_fi_tdt/Udify/\n",
            "models_fi_tdt/Udify/tdt-udify-model.tar.gz\n",
            "models_fi_tdt/Udify/weights.th\n",
            "models_fi_tdt/Udify/vocabulary/\n",
            "models_fi_tdt/Udify/vocabulary/head_tags.txt\n",
            "models_fi_tdt/Udify/vocabulary/feats.txt\n",
            "models_fi_tdt/Udify/vocabulary/token_characters.txt\n",
            "models_fi_tdt/Udify/vocabulary/tokens.txt\n",
            "models_fi_tdt/Udify/vocabulary/upos.txt\n",
            "models_fi_tdt/Udify/vocabulary/xpos.txt\n",
            "models_fi_tdt/Udify/vocabulary/non_padded_namespaces.txt\n",
            "models_fi_tdt/Udify/vocabulary/lemmas.txt\n",
            "models_fi_tdt/Udify/config.json\n",
            "models_fi_tdt/pipelines.yaml\n",
            "models_fi_tdt/README\n",
            "models_fi_tdt/Lemmatizer/\n",
            "models_fi_tdt/Lemmatizer/lemmatizer.pt\n",
            "models_fi_tdt/Tokenizer/\n",
            "models_fi_tdt/Tokenizer/tokenizer.udpipe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpRs20VfbLT2"
      },
      "source": [
        "# Running the parser\n",
        "\n",
        "* Every model can specify many processing pipelines\n",
        "* These are in `modeldir/pipelines.yaml`\n",
        "* `parse_plaintext`is the default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jCpvDULxW8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2a793b-6b26-4497-dc81-f25dfd9c5209"
      },
      "source": [
        "from tnparser.pipeline import read_pipelines, Pipeline\n",
        "\n",
        "available_pipelines=read_pipelines(\"models_fi_tdt/pipelines.yaml\")\n",
        "print(list(available_pipelines.keys()))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['parse_plaintext', 'parse_sentlines', 'parse_wslines', 'parse_conllu', 'tokenize']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeFgUzS5dLKp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            "3b021fa78cd04691854bd38fa26feac3",
            "2bf52f6d9d654a67ad5b83d7714a2f94",
            "5a735b6868eb457cb5c70617a5a0001f",
            "150045ba57844f6398c2e581872a3de1",
            "da2e42939a474f0ebe2baf385a330059",
            "16888e78287540a482ecc04b8568ae0e",
            "d07cdb088a324346bc45b4dda510fd19",
            "9a8205f6e4424dbb806d5ac9efc2b5c9"
          ]
        },
        "outputId": "1062216e-d39e-4a0e-b418-98f2a18e8443"
      },
      "source": [
        "p=Pipeline(available_pipelines[\"parse_plaintext\"])\n",
        "parsed=p.parse(\"Minulla on ruskea koira! Se haukkuu ja juoksee. Voi että!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b021fa78cd04691854bd38fa26feac3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=424343.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset reader: <class 'udify.dataset_readers.universal_dependencies.UniversalDependenciesDatasetReader'>\n",
            "0it [00:00, ?it/s]Your label namespace was 'upos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "Your label namespace was 'xpos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "Your label namespace was 'feats'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "Your label namespace was 'lemmas'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "3it [00:00, 182.04it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_indexer.py:119: FutureWarning: Using a Field with pad_token_sequence, which will be depreciated in 1.0.0.Please implement as_padded_tensor instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/udify/models/dependency_decoder.py:493: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
            "  normalized_arc_logits.unsqueeze(1) + normalized_pairwise_head_logits\n",
            "Encountered the arc_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
            "Encountered the tag_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
            "Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
            " >>> 12/13 unique tokens submitted to lemmatizer\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: OrderedIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqZokOvhd7KW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3f52e6-0a86-4fcd-8083-bc1a71ec45a6"
      },
      "source": [
        "print(parsed)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\tMinulla\tminä\tPRON\t_\tCase=Ade|Number=Sing|Person=1|PronType=Prs\t0\troot\t_\t_\n",
            "2\ton\tolla\tAUX\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\t1\tcop:own\t_\t_\n",
            "3\truskea\truskea\tADJ\t_\tCase=Nom|Degree=Pos|Number=Sing\t4\tamod\t_\t_\n",
            "4\tkoira\tkoira\tNOUN\t_\tCase=Nom|Number=Sing\t1\tnsubj:cop\t_\t_\n",
            "5\t!\t!\tPUNCT\t_\t_\t1\tpunct\t_\t_\n",
            "\n",
            "1\tSe\tse\tPRON\t_\tCase=Nom|Number=Sing|PronType=Dem\t2\tnsubj\t_\t_\n",
            "2\thaukkuu\thaukkua\tVERB\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\t0\troot\t_\t_\n",
            "3\tja\tja\tCCONJ\t_\t_\t4\tcc\t_\t_\n",
            "4\tjuoksee\tjuosta\tVERB\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\t2\tconj\t_\t_\n",
            "5\t.\t.\tPUNCT\t_\t_\t2\tpunct\t_\t_\n",
            "\n",
            "1\tVoi\tvoi\tINTJ\t_\t_\t0\troot\t_\t_\n",
            "2\tettä\tettä\tINTJ\t_\t_\t1\tfixed\t_\t_\n",
            "3\t!\t!\tPUNCT\t_\t_\t1\tpunct\t_\t_\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bXEDdThfM-Z"
      },
      "source": [
        "# GPU mode\n",
        "\n",
        "* The pipeline runs by default in CPU mode\n",
        "* Needs to be told to run in GPU\n",
        "* This is a bit tricky right now but not impossible\n",
        "* Note: if you now switch the Runtime into GPU, you need to re-run the pip install\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt3slQjCfoEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30670512-72f6-4a79-b652-61865fc7fde1"
      },
      "source": [
        "#I do realize this ain't good! :)\n",
        "import types\n",
        "extra_args=types.SimpleNamespace()\n",
        "extra_args.__dict__[\"udify_mod.device\"]=\"0\" #simulates someone giving a --device 0 parameter to Udify\n",
        "extra_args.__dict__[\"lemmatizer_mod.device\"]=\"0\" \n",
        "\n",
        "p=Pipeline(available_pipelines[\"parse_plaintext\"],extra_args)\n",
        "parsed=p.parse(\"Minulla on ruskea koira! Se haukkuu ja juoksee. Voi että!\")\n",
        "print(\"Parsed has this many lines:\",len(parsed.split(\"\\n\")))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset reader: <class 'udify.dataset_readers.universal_dependencies.UniversalDependenciesDatasetReader'>\n",
            "0it [00:00, ?it/s]Your label namespace was 'upos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "Your label namespace was 'xpos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "Your label namespace was 'feats'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "Your label namespace was 'lemmas'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "3it [00:00, 217.47it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_indexer.py:119: FutureWarning: Using a Field with pad_token_sequence, which will be depreciated in 1.0.0.Please implement as_padded_tensor instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/udify/models/dependency_decoder.py:493: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
            "  normalized_arc_logits.unsqueeze(1) + normalized_pairwise_head_logits\n",
            "Encountered the arc_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
            "Encountered the tag_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
            "Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
            " >>> 12/13 unique tokens submitted to lemmatizer\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: OrderedIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Parsed has this many lines: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRGxN0bN1Nev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99afe726-6580-4000-abd2-464c8182a8c1"
      },
      "source": [
        "#Since we are on a GPU, we can try to push through quite a bit more of data\n",
        "parsed=p.parse(\"Minulla on ruskea koira! Se haukkuu ja juoksee. Voi että! \"*200) #takes forever on CPU, finishes in few seconds on GPU\n",
        "print(\"Parsed has this many lines:\",len(parsed.split(\"\\n\")))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsed has this many lines: 3201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G90KC9dFfp-h"
      },
      "source": [
        "# Process the output\n",
        "\n",
        "* The output of the pipeline run is a conll-u string\n",
        "* You can parse it in any number of ways\n",
        "* This is my preferred:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enQ-xvnff599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231f0586-0b74-4347-a7b2-e7a781477e6e"
      },
      "source": [
        "ID,FORM,LEMMA,UPOS,XPOS,FEAT,HEAD,DEPREL,DEPS,MISC=range(10) #the 10 columns\n",
        "\n",
        "def read_conll(inp,max_sent=0,drop_tokens=True,drop_nulls=True):\n",
        "    \"\"\"\n",
        "    inp: list of lines or an open file\n",
        "    max_sent: 0 for all, >0 to limit\n",
        "    drop_tokens: ignore multiword token lines\n",
        "    drop_nulls: ignore null nodes in enhanced dependencies\n",
        "\n",
        "    Yields lines of the parse and comments\n",
        "    \"\"\"\n",
        "\n",
        "    comments=[]\n",
        "    sent=[]\n",
        "    yielded=0\n",
        "    for line in inp:\n",
        "        line=line.rstrip(\"\\n\")\n",
        "        if line.startswith(\"#\"):\n",
        "            comments.append(line)\n",
        "        elif not line:\n",
        "            if sent:\n",
        "                yield sent,comments\n",
        "                yielded+=1\n",
        "                if max_sent>0 and yielded==max_sent:\n",
        "                    break\n",
        "                sent,comments=[],[]\n",
        "        else:\n",
        "            cols=line.split(\"\\t\")\n",
        "            if drop_tokens and \"-\" in cols[ID]:\n",
        "                continue\n",
        "            if drop_nulls and \".\" in cols[ID]:\n",
        "                continue\n",
        "            sent.append(cols)\n",
        "    else:\n",
        "        if sent:\n",
        "            yield sent,comments\n",
        "\n",
        "for one_sent,comments in read_conll(parsed.split(\"\\n\"),5):\n",
        "    words=(word_line[FORM] for word_line in one_sent)\n",
        "    lemmas=(word_line[LEMMA] for word_line in one_sent)\n",
        "    print(\" \".join(words))\n",
        "    print(\" \".join(lemmas))\n",
        "    print()\n",
        "\n",
        "# and that's really all there is to it :)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minulla on ruskea koira !\n",
            "minä olla ruskea koira !\n",
            "\n",
            "Se haukkuu ja juoksee .\n",
            "se haukkua ja juosta .\n",
            "\n",
            "Voi että !\n",
            "voi että !\n",
            "\n",
            "Minulla on ruskea koira !\n",
            "minä olla ruskea koira !\n",
            "\n",
            "Se haukkuu ja juoksee .\n",
            "se haukkua ja juosta .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}